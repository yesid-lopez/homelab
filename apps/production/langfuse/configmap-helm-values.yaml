apiVersion: v1
kind: ConfigMap
metadata:
  name: langfuse-helm-chart-value-overrides
  namespace: langfuse
data:
  values.yaml: |-
    # Langfuse configuration
    langfuse:
      resources:
        limits:
          cpu: "1"
          memory: "2Gi"
        requests:
          cpu: "500m"
          memory: "1Gi"
      
      ingress:
        enabled: true
        className: "nginx"
        hosts:
        - host: langfuse.yesidlopez.de
          paths:
          - path: /
            pathType: Prefix
        annotations:
          cert-manager.io/cluster-issuer: acme-issuer
          nginx.ingress.kubernetes.io/ssl-redirect: "true"
          external-dns.alpha.kubernetes.io/target: "homelab.yesidlopez.de"
        tls:
          enabled: true
          secretName: langfuse-tls

    # Use external PostgreSQL cluster
    postgresql:
      deploy: false
      host: langfuse-postgres-rw.langfuse.svc.cluster.local

    # Redis configuration
    redis:
      primary:
        resources:
          limits:
            cpu: "500m"
            memory: "512Mi"
          requests:
            cpu: "250m"
            memory: "256Mi"
      auth:
        enabled: true

    # ClickHouse configuration
    clickhouse:
      replicaCount: 1
      resources:
        limits:
          cpu: "1"
          memory: "4Gi"
        requests:
          cpu: "500m"
          memory: "2Gi"
      auth:
        enabled: true
      shards: 1
      zookeeper:
        enabled: false
      extraOverrides: |
        <clickhouse>
          <!-- Log retention settings to prevent excessive disk usage -->
          <query_log>
            <ttl>event_date + INTERVAL 7 DAY DELETE</ttl>
          </query_log>
          <trace_log>
            <ttl>event_date + INTERVAL 1 DAY DELETE</ttl>
          </trace_log>
          <query_thread_log>
            <ttl>event_date + INTERVAL 7 DAY DELETE</ttl>
          </query_thread_log>
          <text_log>
            <ttl>event_date + INTERVAL 3 DAY DELETE</ttl>
          </text_log>
          <!-- Increase drop table size limit to allow cleanup of large logs -->
          <max_table_size_to_drop>107374182400</max_table_size_to_drop>
          <max_partition_size_to_drop>107374182400</max_partition_size_to_drop>
        </clickhouse>

    # Global storage class
    global:
      defaultStorageClass: "longhorn"

    # S3/MinIO Configuration
    s3:
      # Enable MinIO deployment (via Bitnami Helm Chart)
      deploy: true
      
      # Storage provider to use
      storageProvider: "s3"
      
      # S3 bucket to use for all uploads
      bucket: "langfuse"
      
      # S3 region to use for all uploads
      region: "auto"
      
      # S3 endpoint to use for all uploads
      endpoint: "http://langfuse-s3:9000"
      
      # Whether to force path style on requests (required for MinIO)
      forcePathStyle: true
      
      # S3 accessKeyId to use for all uploads
      accessKeyId:
        secretKeyRef:
          name: "langfuse-s3"
          key: "root-user"
      
      # S3 secretAccessKey to use for all uploads
      secretAccessKey:
        secretKeyRef:
          name: "langfuse-s3"
          key: "root-password" 
